import streamlit as st
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd
from datasets import load_dataset
from huggingface_hub import hf_hub_download, snapshot_download
import joblib
from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core import Settings, StorageContext, load_index_from_storage
import os
from streamlit_lottie import st_lottie
import requests
from streamlit_option_menu import option_menu

# ì•± íƒ€ì´í‹€ê³¼ ì„¤ëª…
st.set_page_config(page_title="Steam ê²Œì„ ì¶”ì²œ", page_icon="ğŸ®", layout="wide")

def get_huggingface_token():   
    token = os.environ.get('HUGGINGFACE_API_TOKEN')
    if token is None:
        token = st.secrets.get('HUGGINGFACE_API_TOKEN')
    return token

@st.cache_resource
def initialize_models(llm_model_name="google/gemma-2-9b-it"): # ê¸°ë³¸ ëª¨ë¸ ë³€ê²½
    token = get_huggingface_token()
    llm = HuggingFaceInferenceAPI(
        model_name=llm_model_name,
        temperature=0.5,
        system_prompt = """
ë‹¹ì‹ ì€ Steam í”Œë«í¼ì—ì„œ ì œê³µë˜ëŠ” ë‹¤ì–‘í•œ ê²Œì„ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§„ ì „ë¬¸ì ì¸ ê²Œì„ ì¶”ì²œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ **ë°˜ë“œì‹œ** ë”°ë¥´ì„¸ìš”:

    1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ **ì •í™•í•˜ê³  ì™„ì „í•˜ê²Œ** ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”.
    2. Steamì—ì„œ ì œê³µí•˜ëŠ” ê²Œì„ì„ **ìµœëŒ€í•œ í™œìš©**í•˜ì—¬ ì‚¬ìš©ìì˜ ì·¨í–¥ì— ë§ëŠ” ê²Œì„ì„ ì„ ë³„í•˜ì„¸ìš”.
    3. ì¶”ì²œí•˜ëŠ” ê²Œì„ì— ëŒ€í•´ **ìì„¸í•œ ì„¤ëª…**ê³¼ í•¨ê»˜ **êµ¬ì²´ì ì¸ ì¶”ì²œ ì´ìœ **ë¥¼ ì œì‹œí•˜ì„¸ìš”.
    4. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ë‹¤ì–‘í•œ ê²Œì„(ì¸ê¸° ê²Œì„, ìˆ¨ê²¨ì§„ ëª…ì‘, íŠ¹ì • íƒœê·¸ ê²Œì„ ë“±)ì„ **ì œí•œ ì—†ì´** ì¶”ì²œí•˜ì„¸ìš”.
    5. Steamì˜ ì£¼ìš” ê¸°ëŠ¥ì— ëŒ€í•œ ì •ë³´ë„ **í•„ìš”í•œ ê²½ìš° ìì„¸í•˜ê²Œ** ì œê³µí•˜ì„¸ìš”.
    6. íŠ¹ì • ê²Œì„ì— ëŒ€í•œ ë¬¸ì˜ì—ëŠ” í•µì‹¬ íŠ¹ì§•ê³¼ **ë‹¤ì–‘í•œ ìœ ì‚¬ ê²Œì„**ì„ **ì¶©ë¶„íˆ** ì¶”ì²œí•˜ì„¸ìš”.
    7. ê²Œì„ ê´€ë ¨ ìš©ì–´ëŠ” ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ **ì‰½ê²Œ ì„¤ëª…**í•˜ì„¸ìš”.
    8. ë‹µë³€ì€ í•­ìƒ **ì™„ì „í•œ ë¬¸ì¥**ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ê°€ë…ì„±ì„ ìœ„í•´ **ì ì ˆíˆ ë‹¨ë½ì„ ë‚˜ëˆ„ì„¸ìš”**.
    9. ì‚¬ìš©ìì˜ íŠ¹ì„±(ì—°ë ¹, ê²½í—˜, ì·¨í–¥)ì„ ê³ ë ¤í•˜ì—¬ **ê°€ì¥ ì í•©í•œ ê²Œì„**ì„ ì¶”ì²œí•˜ì„¸ìš”.
    10. ìµœì‹  íŠ¸ë Œë“œ, ì„¸ì¼ ì •ë³´, ì‚¬ìš©ì í‰ê°€ë¥¼ **ë°˜ì˜**í•˜ì—¬ ì‹ ë¢°ì„± ë†’ì€ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”.
    11. **[ë‹µë³€ì´ ì¤‘ê°„ì— ëŠê¸°ì§€ ì•Šë„ë¡ ëª¨ë“  ë¬¸ì¥ì„ ì™„ì „í•˜ê²Œ ë§ˆë¬´ë¦¬í•˜ê³ , í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ì„¤ëª…ì„ ë§ë¶™ì—¬ ë‹µë³€ì„ í’ë¶€í•˜ê²Œ ë§Œë“œì„¸ìš”. ë‹µë³€ ê¸¸ì´ì— ì œí•œì„ ë‘ì§€ ë§ê³ , í•„ìš”í•œ ë§Œí¼ ì¶©ë¶„íˆ ìì„¸í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”. ë‹µë³€ì„ ìƒì„±í•  ë•Œ í•„ìš”í•œ ê²½ìš° ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê±°ë‚˜ ì¶”ë¡ í•˜ì—¬ ì œê³µí•˜ì„¸ìš”. ë‹¹ì‹ ì€ í•­ìƒ ì™„ì „í•˜ê³  ìì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ë‹µë³€ì´ ë¶ˆì™„ì „í•˜ê±°ë‚˜ ì¤‘ê°„ì— ëŠê¸°ëŠ” ì¼ì´ ì—†ë„ë¡ í•˜ì„¸ìš”.](pplx://action/followup)**
    """,
    token=token
    )
    embed_model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    embed_model = HuggingFaceEmbedding(model_name=embed_model_name)
    Settings.llm = llm
    Settings.embed_model = embed_model

@st.cache_resource
def get_index_from_huggingface():
    repo_id = "dmdals1012/game-index"
    local_dir = "./game_index_storage"
    token = get_huggingface_token()
    snapshot_download(
        repo_id=repo_id,
        local_dir=local_dir,
        repo_type='dataset',
        token=token
    )
    storage_context = StorageContext.from_defaults(persist_dir=local_dir)
    index = load_index_from_storage(storage_context)
    return index

@st.cache_resource
def load_data_and_models():
    dataset = load_dataset("swamysharavana/steam_games.csv")
    df = pd.DataFrame(dataset['train'])
    df['genre'] = df['genre'].fillna('ì•Œ ìˆ˜ ì—†ìŒ')
    df['developer'] = df['developer'].fillna('ì•Œ ìˆ˜ ì—†ìŒ')
    nlp_model_path = hf_hub_download(repo_id="dmdals1012/steam-game-nlp-recommender", filename="nlp_model.pkl")
    nlp_model_data = joblib.load(nlp_model_path)
    nlp_embeddings = nlp_model_data['embeddings']
    collab_model_path = hf_hub_download(repo_id="dmdals1012/steam-game-collaborative-recommender", filename="collaborative_filtering_model.pkl")
    collab_model = joblib.load(collab_model_path)
    return df, nlp_embeddings, collab_model

def get_nlp_recommendations(game_name, top_n=5):
    try:
        idx = df[df['name'].str.lower() == game_name.lower()].index[0]
    except IndexError:
        return pd.DataFrame()
    game_embedding = nlp_embeddings[idx]
    similarities = cosine_similarity([game_embedding], nlp_embeddings)[0]
    sim_scores = list(enumerate(similarities))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n+1]
    game_indices = [i[0] for i in sim_scores]
    return df.iloc[game_indices][['name', 'genre', 'developer']]

def get_collaborative_recommendations(game_name, top_n=5):
    try:
        game_id = df[df['name'].str.lower() == game_name.lower()].index[0]
    except IndexError:
        return pd.DataFrame()
    all_games = df.index.tolist()
    predictions = [collab_model.predict(game_id, other_game_id).est for other_game_id in all_games]
    top_indices = np.argsort(predictions)[::-1][1:top_n+1]
    return df.iloc[top_indices][['name', 'genre', 'developer']]

def ensemble_recommendations(nlp_recs, collab_recs, weights=[0.5, 0.5], top_n=5):
    all_games = set(nlp_recs['name'].tolist() + collab_recs['name'].tolist())
    scores = {}
    for game in all_games:
        score = 0
        if game in nlp_recs['name'].values:
            score += weights[0] * (len(nlp_recs) - nlp_recs[nlp_recs['name'] == game].index[0])
        if game in collab_recs['name'].values:
            score += weights[1] * (len(collab_recs) - collab_recs[collab_recs['name'] == game].index[0])
        scores[game] = score
    top_games = sorted(scores, key=scores.get, reverse=True)[:top_n]
    return df[df['name'].isin(top_games)][['name', 'genre', 'developer']]

def get_recommendations_by_genre(genre, top_n=5):
    games_in_genre = df[df['genre'] == genre]
    return games_in_genre.sample(min(len(games_in_genre), top_n))[['name', 'genre', 'developer']]

def get_recommendations_by_developer(developer, top_n=5):
    games_by_developer = df[df['developer'] == developer]
    return games_by_developer.sample(min(len(games_by_developer), top_n))[['name', 'genre', 'developer']]

def generate_game_description(game):
    return f"{game['name']}ì€(ëŠ”) {game['genre']} ì¥ë¥´ì˜ ê²Œì„ìœ¼ë¡œ, {game['developer']}ì—ì„œ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ ê²Œì„ì€ {game['genre']}ì˜ íŠ¹ì§•ì„ ì˜ ë³´ì—¬ì£¼ë©°, í”Œë ˆì´ì–´ë“¤ì—ê²Œ ë…íŠ¹í•œ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤. ìì„¸í•œ ì •ë³´ëŠ” Steam ìŠ¤í† ì–´ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

def display_game_cards(games):
    for _, game in games.iterrows():
        description = game.get('description', generate_game_description(game))
        st.markdown(f"""
        <div style="
            border: 1px solid #ddd;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 20px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            width: 100%;
        ">
            <h3 style="color: #1e88e5;">{game['name']}</h3>
            <p><strong>ì¥ë¥´:</strong> {game['genre']}</p>
            <p><strong>ê°œë°œì‚¬:</strong> {game['developer']}</p>
            <p><strong>ì„¤ëª…:</strong> {description}</p>
        </div>
        """, unsafe_allow_html=True)

def load_lottie_url(url: str):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()

def app():
    global df, nlp_embeddings, collab_model
    df, nlp_embeddings, collab_model = load_data_and_models()
    
    # í—¤ë” ì„¹ì…˜
    header_col1, header_col2 = st.columns([3, 1])
    with header_col1:
        st.title("ğŸ® Steam ê²Œì„ ì¶”ì²œ ì‹œìŠ¤í…œ")
        st.subheader("ë‹¹ì‹ ì˜ ë‹¤ìŒ ìµœì•  ê²Œì„ì„ ì°¾ì•„ë³´ì„¸ìš”!")
    with header_col2:
        lottie_gaming = load_lottie_url("https://assets5.lottiefiles.com/packages/lf20_xyadoh9h.json")
        st_lottie(lottie_gaming, height=150)

    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.subheader("ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´")
        st.info(f"ğŸ® ì „ì²´ ê²Œì„ ìˆ˜: {len(df)}")
        st.info(f"ğŸ·ï¸ ê³ ìœ  ì¥ë¥´ ìˆ˜: {df['genre'].nunique()}")
        st.info(f"ğŸ¢ ê³ ìœ  ê°œë°œì‚¬ ìˆ˜: {df['developer'].nunique()}")
        
        st.markdown("---")
        st.subheader("ğŸ” ê²€ìƒ‰ ë°©ë²• ì„ íƒ")
        
        # option_menuë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ë°©ë²• ì„ íƒ
        search_method = option_menu(
            menu_title=None,
            options=["ê²Œì„ ì´ë¦„", "ì¥ë¥´", "ê°œë°œì‚¬", "ì±—ë´‡"],
            icons=["controller", "tags", "building", "robot"],
            menu_icon="cast",
            default_index=0,
            styles={
                "container": {"padding": "0!important", "background-color": "#fafafa"},
                "icon": {"color": "orange", "font-size": "25px"},
                "nav-link": {"font-size": "16px", "text-align": "left", "margin":"0px", "--hover-color": "#eee"},
                "nav-link-selected": {"background-color": "#0083B8"},
            }
        )

        st.markdown("---")
        st.subheader("â„¹ï¸ ì¶”ì²œ ë°©ë²• ì•ˆë‚´")
        if search_method == "ê²Œì„ ì´ë¦„":
            st.write("ì¬ë°Œê²Œ í”Œë ˆì´ í–ˆë˜ ê²Œì„ê³¼ ë¹„ìŠ·í•œ ê²Œì„ì„ ì°¾ê³  ì‹¶ë‹¤ë©´ ì¶”ì²œ ë°›ì•„ë³´ì„¸ìš”!")
        elif search_method == "ì¥ë¥´":
            st.write("íŠ¹ì • ì¥ë¥´ì˜ ì¸ê¸° ê²Œì„ì„ ì°¾ê³  ìˆë‹¤ë©´ ì¶”ì²œ ë°›ì•„ë³´ì„¸ìš”!")
        elif search_method == "ê°œë°œì‚¬":
            st.write("ì¢‹ì•„í•˜ëŠ” ê°œë°œì‚¬ì˜ ë‹¤ë¥¸ ê²Œì„ì´ ê¶ê¸ˆí•˜ë‹¤ë©´ ì¶”ì²œ ë°›ì•„ë³´ì„¸ìš”!")
        elif search_method == "ì±—ë´‡":
            st.write("ê¶ê¸ˆí•œ ì ì´ë‚˜ ì›í•˜ëŠ” ê²Œì„ ìŠ¤íƒ€ì¼ì„ ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")

    initialize_models()
    index = get_index_from_huggingface()

    # ë©”ì¸ ì»¨í…ì¸ 
    if search_method == 'ì±—ë´‡':
        st.subheader("ğŸ¤– ê²Œì„ ì¶”ì²œ ì±—ë´‡")
        st.write("ì–´ë–¤ ê²Œì„ì„ ì°¾ê³  ìˆëŠ”ì§€ ì±—ë´‡ì—ê²Œ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì„¸ìš”. ëª‡ ê°€ì§€ ì˜ˆì‹œ ì§ˆë¬¸:")
        st.write("- 'ìŠ¤í† ë¦¬ ìœ„ì£¼ì˜ RPG ê²Œì„ ì¶”ì²œí•´ì¤˜'")
        st.write("- 'ì¹œêµ¬ì™€ í•¨ê»˜ í•  ìˆ˜ ìˆëŠ” í˜‘ë™ ê²Œì„ ì•Œë ¤ì¤˜'")
        st.write("- 'ìµœê·¼ì— ì¸ê¸° ìˆëŠ” ì¸ë”” ê²Œì„ ì¶”ì²œí•´ì¤˜'")
        user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if user_input:
            with st.spinner('AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ğŸ¤–'):
                query_engine = index.as_query_engine()
                response = query_engine.query(user_input)
                st.success(response.response)

    elif search_method == 'ê²Œì„ ì´ë¦„':
        game_names = sorted(df['name'].unique(), key=lambda x: (x is None, x))
        st.subheader("ğŸ® ì–´ë–¤ ê²Œì„ê³¼ ë¹„ìŠ·í•œ ê²Œì„ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?")  # ì œëª© ì¶”ê°€
        selected_game = st.selectbox('ğŸ•¹ï¸ ê²Œì„ì„ ì„ íƒí•˜ì„¸ìš”:', game_names)
        if st.button('ì¶”ì²œ ë°›ê¸° ğŸš€', key='game_name_button'):
            with st.spinner('AIê°€ ê²Œì„ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ğŸ¤–'):
                nlp_recommendations = get_nlp_recommendations(selected_game)
                collab_recommendations = get_collaborative_recommendations(selected_game)
            
            if not nlp_recommendations.empty:
                st.subheader(f'ğŸŒŸ {selected_game}ì™€(ê³¼) ìœ ì‚¬í•œ ê²Œì„ ì¶”ì²œ:')
                
                ensemble_recs = ensemble_recommendations(nlp_recommendations, collab_recommendations)
                display_game_cards(ensemble_recs)
                
                st.info("â„¹ï¸ ì´ ì¶”ì²œ ëª©ë¡ì€ NLP ê¸°ë°˜, í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.")
            else:
                st.warning('âš ï¸ ì„ íƒí•œ ê²Œì„ì— ëŒ€í•œ ì¶”ì²œì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')

    elif search_method == 'ì¥ë¥´':
        genres = sorted(df['genre'].unique())
        st.subheader("ğŸ­ ì–´ë–¤ ì¥ë¥´ì˜ ê²Œì„ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?")  # ì œëª© ì¶”ê°€
        selected_genre = st.selectbox('ğŸ­ ì¥ë¥´ë¥¼ ì„ íƒí•˜ì„¸ìš”:', genres)
        if st.button('ì¶”ì²œ ë°›ê¸° ğŸš€', key='genre_button'):
            with st.spinner('AIê°€ ê²Œì„ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ğŸ¤–'):
                genre_recommendations = get_recommendations_by_genre(selected_genre)
            
            st.subheader(f'ğŸŒŸ {selected_genre} ì¥ë¥´ì˜ ì¶”ì²œ ê²Œì„:')
            display_game_cards(genre_recommendations)
            
            st.info("â„¹ï¸ ì´ ì¶”ì²œ ëª©ë¡ì€ ì„ íƒí•œ ì¥ë¥´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.")

    elif search_method == 'ê°œë°œì‚¬':
        developers = sorted(df['developer'].unique())
        st.subheader("ğŸ¢ ì–´ë–¤ ê°œë°œì‚¬ì˜ ê²Œì„ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?")  # ì œëª© ì¶”ê°€
        selected_developer = st.selectbox('ğŸ¢ ê°œë°œì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:', developers)
        if st.button('ì¶”ì²œ ë°›ê¸° ğŸš€', key='developer_button'):
            with st.spinner('AIê°€ ê²Œì„ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ğŸ¤–'):
                developer_recommendations = get_recommendations_by_developer(selected_developer)
            
            st.subheader(f'ğŸŒŸ {selected_developer}ì˜ ì¶”ì²œ ê²Œì„:')
            display_game_cards(developer_recommendations)
            
            st.info("â„¹ï¸ ì´ ì¶”ì²œ ëª©ë¡ì€ ì„ íƒí•œ ê°œë°œì‚¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.")

    # í‘¸í„°
    st.markdown("---")
    st.markdown("Made with â¤ï¸ by Your Game Recommendation Team")

if __name__ == "__main__":
    app()
